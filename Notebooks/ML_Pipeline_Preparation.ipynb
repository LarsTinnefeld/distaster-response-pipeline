{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('disaster_messages', engine)\n",
    "\n",
    "df = df[:200]\n",
    "\n",
    "X = df['message']\n",
    "Y = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct      1.0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct      1.0   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct      1.0   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0      0.0    0.0          0.0           0.0               0.0  ...   \n",
       "1      0.0    0.0          1.0           0.0               0.0  ...   \n",
       "2      0.0    0.0          0.0           0.0               0.0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "1          0.0                   0.0              1.0     0.0    1.0   0.0   \n",
       "2          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0         0.0   0.0            0.0            0.0  \n",
       "1         0.0   0.0            0.0            0.0  \n",
       "2         0.0   0.0            0.0            0.0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>message</th>\n      <th>original</th>\n      <th>genre</th>\n      <th>related</th>\n      <th>request</th>\n      <th>offer</th>\n      <th>aid_related</th>\n      <th>medical_help</th>\n      <th>medical_products</th>\n      <th>...</th>\n      <th>aid_centers</th>\n      <th>other_infrastructure</th>\n      <th>weather_related</th>\n      <th>floods</th>\n      <th>storm</th>\n      <th>fire</th>\n      <th>earthquake</th>\n      <th>cold</th>\n      <th>other_weather</th>\n      <th>direct_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Weather update - a cold front from Cuba that c...</td>\n      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n      <td>direct</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>Is the Hurricane over or is it not over</td>\n      <td>Cyclone nan fini osinon li pa fini</td>\n      <td>direct</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>Looking for someone but no name</td>\n      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n      <td>direct</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 40 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "4    says: west side of Haiti, rest of the country ...\n",
       "Name: message, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0      1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "1      1.0      0.0    0.0          1.0           0.0               0.0   \n",
       "2      1.0      0.0    0.0          0.0           0.0               0.0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "1                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "2                0.0       0.0       0.0          0.0  ...          0.0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "1                   0.0              1.0     0.0    1.0   0.0         0.0   \n",
       "2                   0.0              0.0     0.0    0.0   0.0         0.0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0   0.0            0.0            0.0  \n",
       "1   0.0            0.0            0.0  \n",
       "2   0.0            0.0            0.0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>related</th>\n      <th>request</th>\n      <th>offer</th>\n      <th>aid_related</th>\n      <th>medical_help</th>\n      <th>medical_products</th>\n      <th>search_and_rescue</th>\n      <th>security</th>\n      <th>military</th>\n      <th>child_alone</th>\n      <th>...</th>\n      <th>aid_centers</th>\n      <th>other_infrastructure</th>\n      <th>weather_related</th>\n      <th>floods</th>\n      <th>storm</th>\n      <th>fire</th>\n      <th>earthquake</th>\n      <th>cold</th>\n      <th>other_weather</th>\n      <th>direct_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "Y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 200 entries, 0 to 199\nData columns (total 40 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   id                      200 non-null    int64  \n 1   message                 200 non-null    object \n 2   original                200 non-null    object \n 3   genre                   200 non-null    object \n 4   related                 200 non-null    float64\n 5   request                 200 non-null    float64\n 6   offer                   200 non-null    float64\n 7   aid_related             200 non-null    float64\n 8   medical_help            200 non-null    float64\n 9   medical_products        200 non-null    float64\n 10  search_and_rescue       200 non-null    float64\n 11  security                200 non-null    float64\n 12  military                200 non-null    float64\n 13  child_alone             200 non-null    float64\n 14  water                   200 non-null    float64\n 15  food                    200 non-null    float64\n 16  shelter                 200 non-null    float64\n 17  clothing                200 non-null    float64\n 18  money                   200 non-null    float64\n 19  missing_people          200 non-null    float64\n 20  refugees                200 non-null    float64\n 21  death                   200 non-null    float64\n 22  other_aid               200 non-null    float64\n 23  infrastructure_related  200 non-null    float64\n 24  transport               200 non-null    float64\n 25  buildings               200 non-null    float64\n 26  electricity             200 non-null    float64\n 27  tools                   200 non-null    float64\n 28  hospitals               200 non-null    float64\n 29  shops                   200 non-null    float64\n 30  aid_centers             200 non-null    float64\n 31  other_infrastructure    200 non-null    float64\n 32  weather_related         200 non-null    float64\n 33  floods                  200 non-null    float64\n 34  storm                   200 non-null    float64\n 35  fire                    200 non-null    float64\n 36  earthquake              200 non-null    float64\n 37  cold                    200 non-null    float64\n 38  other_weather           200 non-null    float64\n 39  direct_report           200 non-null    float64\ndtypes: float64(36), int64(1), object(3)\nmemory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''Function that takes in a text splits with white spaces and creates list of words'''\n",
    "    text = text.lower() \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    word_list = nltk.tokenize.word_tokenize(text)\n",
    "    word_list = [n for n in word_list if n not in stopwords.words(\"english\")]\n",
    "    \n",
    "    lemmed_list = [WordNetLemmatizer().lemmatize(n, pos='v') for n in word_list]\n",
    "    \n",
    "    return lemmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello', 'world', 'test']"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "test_text = 'Hello world. This is just a test'\n",
    "tokenize(test_text)"
   ]
  },
  {
   "source": [
    "Works!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the machine learning model\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "        ])"
   ]
  },
  {
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one: Split into train- and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model to train is \"pipeline\"\n",
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Category: related\n              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00        12\n         1.0       0.82      1.00      0.90        54\n\n    accuracy                           0.82        66\n   macro avg       0.41      0.50      0.45        66\nweighted avg       0.67      0.82      0.74        66\n\nCategory: request\n              precision    recall  f1-score   support\n\n         0.0       0.83      0.16      0.26        32\n         1.0       0.55      0.97      0.70        34\n\n    accuracy                           0.58        66\n   macro avg       0.69      0.56      0.48        66\nweighted avg       0.69      0.58      0.49        66\n\nCategory: offer\n              precision    recall  f1-score   support\n\n         0.0       0.98      1.00      0.99        65\n         1.0       0.00      0.00      0.00         1\n\n    accuracy                           0.98        66\n   macro avg       0.49      0.50      0.50        66\nweighted avg       0.97      0.98      0.98        66\n\nCategory: aid_related\n              precision    recall  f1-score   support\n\n         0.0       1.00      0.12      0.21        25\n         1.0       0.65      1.00      0.79        41\n\n    accuracy                           0.67        66\n   macro avg       0.83      0.56      0.50        66\nweighted avg       0.78      0.67      0.57        66\n\nCategory: medical_help\n              precision    recall  f1-score   support\n\n         0.0       0.85      1.00      0.92        56\n         1.0       0.00      0.00      0.00        10\n\n    accuracy                           0.85        66\n   macro avg       0.42      0.50      0.46        66\nweighted avg       0.72      0.85      0.78        66\n\nCategory: medical_products\n              precision    recall  f1-score   support\n\n         0.0       0.89      1.00      0.94        59\n         1.0       0.00      0.00      0.00         7\n\n    accuracy                           0.89        66\n   macro avg       0.45      0.50      0.47        66\nweighted avg       0.80      0.89      0.84        66\n\nCategory: search_and_rescue\n              precision    recall  f1-score   support\n\n         0.0       0.94      1.00      0.97        62\n         1.0       0.00      0.00      0.00         4\n\n    accuracy                           0.94        66\n   macro avg       0.47      0.50      0.48        66\nweighted avg       0.88      0.94      0.91        66\n\nCategory: security\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: military\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: child_alone\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: water\n              precision    recall  f1-score   support\n\n         0.0       0.85      1.00      0.92        50\n         1.0       1.00      0.44      0.61        16\n\n    accuracy                           0.86        66\n   macro avg       0.92      0.72      0.76        66\nweighted avg       0.88      0.86      0.84        66\n\nCategory: food\n              precision    recall  f1-score   support\n\n         0.0       0.90      0.92      0.91        50\n         1.0       0.73      0.69      0.71        16\n\n    accuracy                           0.86        66\n   macro avg       0.82      0.80      0.81        66\nweighted avg       0.86      0.86      0.86        66\n\nCategory: shelter\n              precision    recall  f1-score   support\n\n         0.0       0.88      1.00      0.94        58\n         1.0       0.00      0.00      0.00         8\n\n    accuracy                           0.88        66\n   macro avg       0.44      0.50      0.47        66\nweighted avg       0.77      0.88      0.82        66\n\nCategory: clothing\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: money\n              precision    recall  f1-score   support\n\n         0.0       0.95      1.00      0.98        63\n         1.0       0.00      0.00      0.00         3\n\n    accuracy                           0.95        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.91      0.95      0.93        66\n\nCategory: missing_people\n              precision    recall  f1-score   support\n\n         0.0       0.95      1.00      0.98        63\n         1.0       0.00      0.00      0.00         3\n\n    accuracy                           0.95        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.91      0.95      0.93        66\n\nCategory: refugees\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: death\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: other_aid\n              precision    recall  f1-score   support\n\n         0.0       0.77      1.00      0.87        50\n         1.0       1.00      0.06      0.12        16\n\n    accuracy                           0.77        66\n   macro avg       0.88      0.53      0.49        66\nweighted avg       0.83      0.77      0.69        66\n\nCategory: infrastructure_related\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: transport\n              precision    recall  f1-score   support\n\n         0.0       0.94      1.00      0.97        62\n         1.0       0.00      0.00      0.00         4\n\n    accuracy                           0.94        66\n   macro avg       0.47      0.50      0.48        66\nweighted avg       0.88      0.94      0.91        66\n\nCategory: buildings\n              precision    recall  f1-score   support\n\n         0.0       0.95      1.00      0.98        63\n         1.0       0.00      0.00      0.00         3\n\n    accuracy                           0.95        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.91      0.95      0.93        66\n\nCategory: electricity\n              precision    recall  f1-score   support\n\n         0.0       0.98      1.00      0.99        65\n         1.0       0.00      0.00      0.00         1\n\n    accuracy                           0.98        66\n   macro avg       0.49      0.50      0.50        66\nweighted avg       0.97      0.98      0.98        66\n\nCategory: tools\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: hospitals\n              precision    recall  f1-score   support\n\n         0.0       0.98      1.00      0.99        65\n         1.0       0.00      0.00      0.00         1\n\n    accuracy                           0.98        66\n   macro avg       0.49      0.50      0.50        66\nweighted avg       0.97      0.98      0.98        66\n\nCategory: shops\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: aid_centers\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: other_infrastructure\n              precision    recall  f1-score   support\n\n         0.0       0.98      1.00      0.99        65\n         1.0       0.00      0.00      0.00         1\n\n    accuracy                           0.98        66\n   macro avg       0.49      0.50      0.50        66\nweighted avg       0.97      0.98      0.98        66\n\nCategory: weather_related\n              precision    recall  f1-score   support\n\n         0.0       0.86      1.00      0.93        57\n         1.0       0.00      0.00      0.00         9\n\n    accuracy                           0.86        66\n   macro avg       0.43      0.50      0.46        66\nweighted avg       0.75      0.86      0.80        66\n\nCategory: floods\n              precision    recall  f1-score   support\n\n         0.0       0.94      1.00      0.97        62\n         1.0       0.00      0.00      0.00         4\n\n    accuracy                           0.94        66\n   macro avg       0.47      0.50      0.48        66\nweighted avg       0.88      0.94      0.91        66\n\nCategory: storm\n              precision    recall  f1-score   support\n\n         0.0       0.95      1.00      0.98        63\n         1.0       0.00      0.00      0.00         3\n\n    accuracy                           0.95        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.91      0.95      0.93        66\n\nCategory: fire\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: earthquake\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.98        64\n         1.0       0.00      0.00      0.00         2\n\n    accuracy                           0.97        66\n   macro avg       0.48      0.50      0.49        66\nweighted avg       0.94      0.97      0.95        66\n\nCategory: cold\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: other_weather\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        66\n\n    accuracy                           1.00        66\n   macro avg       1.00      1.00      1.00        66\nweighted avg       1.00      1.00      1.00        66\n\nCategory: direct_report\n              precision    recall  f1-score   support\n\n         0.0       0.79      0.62      0.70        37\n         1.0       0.62      0.79      0.70        29\n\n    accuracy                           0.70        66\n   macro avg       0.71      0.71      0.70        66\nweighted avg       0.72      0.70      0.70        66\n\n"
     ]
    }
   ],
   "source": [
    "# print predictions classification_report()\n",
    "for index, column in enumerate(y_test.columns):\n",
    "    print('Category: {}'.format(column))\n",
    "    print(classification_report(y_test[column], pred_test[:,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Category: related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        17\n",
      "         1.0       1.00      1.00      1.00       116\n",
      "         2.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        49\n",
      "         1.0       1.00      1.00      1.00        85\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        45\n",
      "         1.0       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       118\n",
      "         1.0       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       0.99      0.94      0.96       134\n",
      "weighted avg       0.99      0.99      0.98       134\n",
      "\n",
      "Category: medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       126\n",
      "         1.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       128\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       130\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       132\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       101\n",
      "         1.0       1.00      0.97      0.98        33\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       1.00      0.98      0.99       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n",
      "Category: food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99        91\n",
      "         1.0       0.98      1.00      0.99        43\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       0.99      0.99      0.99       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n",
      "Category: shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       125\n",
      "         1.0       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       1.00      0.94      0.97       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n",
      "Category: clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       129\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       130\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       130\n",
      "         1.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       132\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       127\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       103\n",
      "         1.0       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       0.98      1.00      0.99       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n",
      "Category: infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       122\n",
      "         1.0       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       127\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       125\n",
      "         1.0       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       133\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       133\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       132\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       132\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       126\n",
      "         1.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       116\n",
      "         1.0       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       129\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       129\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       131\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       129\n",
      "         1.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       131\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       131\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       134\n",
      "   macro avg       1.00      1.00      1.00       134\n",
      "weighted avg       1.00      1.00      1.00       134\n",
      "\n",
      "Category: direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99        64\n",
      "         1.0       0.99      1.00      0.99        70\n",
      "\n",
      "    accuracy                           0.99       134\n",
      "   macro avg       0.99      0.99      0.99       134\n",
      "weighted avg       0.99      0.99      0.99       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print predictions classification_report()\n",
    "for index, column in enumerate(y_train.columns):\n",
    "    print('Category: {}'.format(column))\n",
    "    print(classification_report(y_train[column], pred_train[:,index]))"
   ]
  },
  {
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the parameters of the pipeline object?\n",
    "params = pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "memory:  None \n",
      "\n",
      "steps:  [('vect', CountVectorizer(tokenizer=<function tokenize at 0x00000260B450A040>)), ('tfidf', TfidfTransformer()), ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))] \n",
      "\n",
      "verbose:  False \n",
      "\n",
      "vect:  CountVectorizer(tokenizer=<function tokenize at 0x00000260B450A040>) \n",
      "\n",
      "tfidf:  TfidfTransformer() \n",
      "\n",
      "clf:  MultiOutputClassifier(estimator=RandomForestClassifier()) \n",
      "\n",
      "vect__analyzer:  word \n",
      "\n",
      "vect__binary:  False \n",
      "\n",
      "vect__decode_error:  strict \n",
      "\n",
      "vect__dtype:  <class 'numpy.int64'> \n",
      "\n",
      "vect__encoding:  utf-8 \n",
      "\n",
      "vect__input:  content \n",
      "\n",
      "vect__lowercase:  True \n",
      "\n",
      "vect__max_df:  1.0 \n",
      "\n",
      "vect__max_features:  None \n",
      "\n",
      "vect__min_df:  1 \n",
      "\n",
      "vect__ngram_range:  (1, 1) \n",
      "\n",
      "vect__preprocessor:  None \n",
      "\n",
      "vect__stop_words:  None \n",
      "\n",
      "vect__strip_accents:  None \n",
      "\n",
      "vect__token_pattern:  (?u)\\b\\w\\w+\\b \n",
      "\n",
      "vect__tokenizer:  <function tokenize at 0x00000260B450A040> \n",
      "\n",
      "vect__vocabulary:  None \n",
      "\n",
      "tfidf__norm:  l2 \n",
      "\n",
      "tfidf__smooth_idf:  True \n",
      "\n",
      "tfidf__sublinear_tf:  False \n",
      "\n",
      "tfidf__use_idf:  True \n",
      "\n",
      "clf__estimator__bootstrap:  True \n",
      "\n",
      "clf__estimator__ccp_alpha:  0.0 \n",
      "\n",
      "clf__estimator__class_weight:  None \n",
      "\n",
      "clf__estimator__criterion:  gini \n",
      "\n",
      "clf__estimator__max_depth:  None \n",
      "\n",
      "clf__estimator__max_features:  auto \n",
      "\n",
      "clf__estimator__max_leaf_nodes:  None \n",
      "\n",
      "clf__estimator__max_samples:  None \n",
      "\n",
      "clf__estimator__min_impurity_decrease:  0.0 \n",
      "\n",
      "clf__estimator__min_impurity_split:  None \n",
      "\n",
      "clf__estimator__min_samples_leaf:  1 \n",
      "\n",
      "clf__estimator__min_samples_split:  2 \n",
      "\n",
      "clf__estimator__min_weight_fraction_leaf:  0.0 \n",
      "\n",
      "clf__estimator__n_estimators:  100 \n",
      "\n",
      "clf__estimator__n_jobs:  None \n",
      "\n",
      "clf__estimator__oob_score:  False \n",
      "\n",
      "clf__estimator__random_state:  None \n",
      "\n",
      "clf__estimator__verbose:  0 \n",
      "\n",
      "clf__estimator__warm_start:  False \n",
      "\n",
      "clf__estimator:  RandomForestClassifier() \n",
      "\n",
      "clf__n_jobs:  None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in params:\n",
    "    print(param + ': ', pipeline.get_params()[param], '\\n')"
   ]
  },
  {
   "source": [
    "#### Selecting some example parameters for the text pipeline:\n",
    "- text_pipeline__vect__max_df:  1.0\n",
    "- text_pipeline__vect__min_df:  1\n",
    "- text_pipeline__vect__max_features:  None\n",
    "- text_pipeline__vect__stop_words:  None\n",
    "- text_pipeline__tfidf__use_idf:  True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Selecting some example parameters for the classifier pipeline:\n",
    "- clf__estimator__max_depth:  None\n",
    "- clf__estimator__min_samples_leaf:  1\n",
    "- clf__estimator__n_estimators:  10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying new parameters for grid search\n",
    "parameters = {\n",
    "    'text_pipeline__vect__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "    #'text_pipeline__vect__min_df': (1, 1.25, 1.5, 1.75),\n",
    "    #'text_pipeline__vect__max_features': (None, 1000, 500),\n",
    "    #'text_pipeline__vect__stop_words': (None, 1000, 200),\n",
    "    'text_pipeline__tfidf__use_idf': (True, False),\n",
    "    #'clf__estimator__max_depth': (None, 1000),\n",
    "    #'clf__estimator__min_samples_leaf': (1, 5, 10),\n",
    "    'clf__estimator__n_estimators': (10, 50, 100)\n",
    "    }\n",
    "\n",
    "# Apply parameters to Gridsearch\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Invalid parameter text_pipeline for estimator Pipeline(steps=[('vect',\n                 CountVectorizer(tokenizer=<function tokenize at 0x00000260B450A040>)),\n                ('tfidf', TfidfTransformer()),\n                ('clf',\n                 MultiOutputClassifier(estimator=RandomForestClassifier()))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-6c976e20f457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \"\"\"\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[1;34m(self, attr, **params)\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[0;32m    250\u001b[0m                                  \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                                  \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter text_pipeline for estimator Pipeline(steps=[('vect',\n                 CountVectorizer(tokenizer=<function tokenize at 0x00000260B450A040>)),\n                ('tfidf', TfidfTransformer()),\n                ('clf',\n                 MultiOutputClassifier(estimator=RandomForestClassifier()))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 9. Export your model as a pickle file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}